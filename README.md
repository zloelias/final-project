# Abstract

Despite impressive advances in NLP in recent years, the technology still needs improvements, such as making models more robust and interpretable. In my work, I will study several types of adversarial attacks on a text classification model. Attacks that distort text at the character level (imitation of typos), replace words with synonyms based on embeddings and masked language models. The aim of the work is to test the applicability of methods to Russian language and compare the results with the English-language attacks.
